{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Train data and Model OCR - Tardigrade.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Train Model OCR - Tardigrade"
      ],
      "metadata": {
        "id": "toUAHITlho1J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preparation"
      ],
      "metadata": {
        "id": "VA95tLRKhsqF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SpqJk2yHgnWi"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mnist = keras.datasets.mnist\n",
        "(train_images_mnist,train_labels_mnist),(test_images_mnist,test_labels_mnist) = mnist.load_data()\n",
        "\n",
        "train_images_mnist = np.reshape(train_images_mnist,(train_images_mnist.shape[0],28,28,1))  \n",
        "test_images_mnist = np.reshape(test_images_mnist,(test_images_mnist.shape[0],28,28,1))"
      ],
      "metadata": {
        "id": "Ycws8AA_gxWD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "az_data_path = 'drive/MyDrive/Atam/Dataset'\n",
        "AZ_data = pd.read_csv(az_data_path +'/A_Z Handwritten Data.csv',header = None)\n",
        "#value label dan input yang ada dibagi berdasarkan variable\n",
        "AZ_labels = AZ_data.values[:,0]\n",
        "AZ_images = AZ_data.values[:,1:]\n",
        "#Mengubah Ukuran supaya dapat digunakan dengan input 28 x 28\n",
        "AZ_images = np.reshape(AZ_images,(AZ_images.shape[0],28,28,1))  \n",
        "\n"
      ],
      "metadata": {
        "id": "x1HgD2gNgyWd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Splitting Data"
      ],
      "metadata": {
        "id": "w9DIuezlh67o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Penggabungan data set\n",
        "# Bagi dataset yang tadi udah dibagi antara train test\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "test_size = float(len(test_labels_mnist))/len(train_labels_mnist)\n",
        "print(f'test set size: {test_size}')\n",
        "train_images_AZ, test_images_AZ, train_labels_AZ, test_labels_AZ,train_test_split(AZ_images,AZ_labels, test_size=test_size)\n",
        "#shift mnist labels \n",
        "train_labels_mnist = train_labels_mnist + max(AZ_labels)+1\n",
        "test_labels_mnist = test_labels_mnist + max(AZ_labels)+1\n",
        "\n",
        "# concatenate datasets\n",
        "train_images = np.concatenate((train_images_AZ,train_images_mnist),axis=0)\n",
        "train_labels = np.concatenate((train_labels_AZ,train_labels_mnist))\n",
        "test_images = np.concatenate((test_images_AZ,test_images_mnist),axis=0)\n",
        "test_labels = np.concatenate((test_labels_AZ,test_labels_mnist))\n",
        "\n",
        "print('Data ready')"
      ],
      "metadata": {
        "id": "ANsV-sNOgzeP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Model"
      ],
      "metadata": {
        "id": "bmW63b23h9oV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "model = tf.keras.models.Sequential([\n",
        "    # Note the input shape is the desired size of the image 150x150 with 3 bytes color\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2), \n",
        "    # Flatten the results to feed into a DNN\n",
        "    tf.keras.layers.Flatten(), \n",
        "    # 512 neuron hidden layer\n",
        "    tf.keras.layers.Dense(512, activation='relu'), \n",
        "    # Only 1 output neuron. It will contain a value from 0-1 where 0 for 1 class ('cats') and 1 for the other ('dogs')\n",
        "    tf.keras.layers.Dense(len(np.unique(train_labels)), activation='softmax')  \n",
        "])\n",
        "\n",
        "model.compile(optimizer=RMSprop(learning_rate=1e-4),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics = ['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "jiAw3XI_g0Ez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create custom tuning ImageGenerator"
      ],
      "metadata": {
        "id": "wBRV-NzLh_ek"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255,\n",
        "      rotation_range=15,\n",
        "      width_shift_range=0.1,\n",
        "      height_shift_range=0.1,\n",
        "      shear_range=0.1,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=False,\n",
        "      fill_mode='nearest')\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "metadata": {
        "id": "06q35T8Ug1hX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Flow training images in batches using generator\n",
        "train_generator = train_datagen.flow(train_images, train_labels, batch_size=50, shuffle=True)\n",
        "validation_generator = test_datagen.flow(test_images, test_labels, batch_size=50, shuffle=True)"
      ],
      "metadata": {
        "id": "xrdvBy7pg2-L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Start training"
      ],
      "metadata": {
        "id": "3VkT3xRuiEml"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "      train_generator,\n",
        "      steps_per_epoch=500,  \n",
        "      epochs=100,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps=50,  \n",
        "      verbose=2)\n",
        "model.save('model_v2')"
      ],
      "metadata": {
        "id": "lwpzDqXYg4uX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Show Graphic"
      ],
      "metadata": {
        "id": "Qjjl-UIhiGX5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# summarize history for accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3s42Gt9Ug6zi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Deployment"
      ],
      "metadata": {
        "id": "fDrZA_RiiMHM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import imutils\n",
        "from imutils.contours import sort_contours"
      ],
      "metadata": {
        "id": "95--hJjtg8mt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loads the model with the keras load_model function\n",
        "model_path = 'model_v2'\n",
        "print(\"Loading NN model...\")\n",
        "model = load_model(model_path)\n",
        "print(\"Done\")"
      ],
      "metadata": {
        "id": "1aUv1eBeg9om"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loads the input image\n",
        "image_path = 'buy.jpeg'\n",
        "image = cv2.imread(image_path)\n",
        "tinggi, lebar = image.shape[:2]\n",
        "#from google.colab import files\n",
        "#image = files.upload() "
      ],
      "metadata": {
        "id": "IFI2FSrrg-tG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "cropped = gray[:,:]\n",
        "hasil = cropped.copy()\n",
        "for x in range (tinggi):\n",
        "    for y in range (lebar):\n",
        "        if cropped[x,y] < 150:\n",
        "            hasil[x,y] = 0\n",
        "        else:\n",
        "            hasil[x,y] = 255\n",
        "\n",
        "blurred1 = cv2.GaussianBlur(hasil, (5, 5), 0)\n",
        "\n",
        "\n",
        "%matplotlib inline\n",
        "from matplotlib import cm\n",
        "fig = plt.figure(figsize=(16,4))\n",
        "ax = plt.subplot(1,4,1)\n",
        "ax.imshow(image)\n",
        "ax.set_title('Original Image');\n",
        "\n",
        "ax = plt.subplot(1,4,2)\n",
        "ax.imshow(gray,cmap=cm.binary_r)\n",
        "ax.set_axis_off()\n",
        "ax.set_title('Grayscale Image');\n",
        "\n",
        "ax = plt.subplot(1,4,3)\n",
        "ax.imshow(cropped,cmap=cm.binary_r)\n",
        "ax.set_axis_off()\n",
        "ax.set_title('Cropped Image');\n",
        "\n",
        "ax = plt.subplot(1,4,4)\n",
        "ax.imshow(blurred1,cmap=cm.binary_r)\n",
        "ax.set_axis_off()\n",
        "ax.set_title('Blurred');\n",
        "#plt.imshow(gray,cmap=cm.binary_r)"
      ],
      "metadata": {
        "id": "fWpk-BE4g_rJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# perform edge detection, find contours in the edge map, and sort the\n",
        "# resulting contours from left-to-right\n",
        "edged1 = cv2.Canny(blurred1, 30, 250) #low_threshold, high_threshold\n",
        "edged =  cv2.GaussianBlur(edged1, (5, 5), 0)\n",
        "cnts = cv2.findContours(edged.copy(), cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
        "cnts = imutils.grab_contours(cnts)\n",
        "cnts = sort_contours(cnts, method=\"left-to-right\")[0]\n",
        "\n",
        "figure = plt.figure(figsize=(7,7))\n",
        "plt.axis('off');\n",
        "plt.imshow(edged,cmap=cm.binary_r);"
      ],
      "metadata": {
        "id": "FqsWcSXUhBCY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chars = []\n",
        "# loop over the contours\n",
        "for c in cnts:\n",
        "\t# compute the bounding box of the contour and isolate ROI\n",
        "  (x, y, w, h) = cv2.boundingRect(c)\n",
        "  roi = cropped[y:y + h, x:x + w]\n",
        "  \n",
        "  #binarize image, finds threshold with OTSU method\n",
        "  thresh = cv2.threshold(roi, 0, 255,cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]\n",
        "  \n",
        "  # resize largest dimension to input size\n",
        "  (tH, tW) = thresh.shape\n",
        "  if tW > tH:\n",
        "    thresh = imutils.resize(thresh, width=28)\n",
        "  # otherwise, resize along the height\n",
        "  else:\n",
        "    thresh = imutils.resize(thresh, height=28)\n",
        "\n",
        "  # find how much is needed to pad\n",
        "  (tH, tW) = thresh.shape\n",
        "  dX = int(max(0, 28 - tW) / 2.0)\n",
        "  dY = int(max(0, 28 - tH) / 2.0)\n",
        "  # pad the image and force 28 x 28 dimensions\n",
        "  padded = cv2.copyMakeBorder(thresh, top=dY, bottom=dY,\n",
        "    left=dX, right=dX, borderType=cv2.BORDER_CONSTANT,\n",
        "    value=(0, 0, 0))\n",
        "  padded = cv2.resize(padded, (28, 28))\n",
        "  # reshape and rescale padded image for the model\n",
        "  padded = padded.astype(\"float32\") / 255.0\n",
        "  padded = np.expand_dims(padded, axis=-1)\n",
        "  # append image and bounding box data in char list\n",
        "  chars.append((padded, (x, y, w, h)))"
      ],
      "metadata": {
        "id": "lHEZnndihCSK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot isolated characters\n",
        "n_cols = 10\n",
        "n_rows = np.floor(len(chars)/ n_cols)+1\n",
        "fig = plt.figure(figsize=(1.5*n_cols,1.5*n_rows))\n",
        "for i,char in enumerate(chars):\n",
        "  ax = plt.subplot(n_rows,n_cols,i+1)\n",
        "  ax.imshow(char[0][:,:,0],cmap=cm.binary,aspect='auto')\n",
        "  #plt.axis('off')\n",
        "plt.tight_layout()"
      ],
      "metadata": {
        "id": "Tq4P0gg8hDdU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "boxes = [b[1] for b in chars]\n",
        "chars = np.array([c[0] for c in chars], dtype=\"float32\")\n",
        "# OCR the characters using our handwriting recognition model\n",
        "preds = model.predict(chars)\n",
        "# define the list of label names\n",
        "labelNames = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789\""
      ],
      "metadata": {
        "id": "iJtk-fgehFcu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image = cv2.imread(image_path)\n",
        "cropped = image[120:,:]\n",
        "\n",
        "for (pred, (x, y, w, h)) in zip(preds, boxes):\n",
        "\t# find the index of the label with the largest corresponding\n",
        "\t# probability, then extract the probability and label\n",
        "  i = np.argmax(pred)\n",
        "  prob = pred[i]\n",
        "  label = labelNames[i]\n",
        "  # draw the prediction on the image and it's probability\n",
        "  label_text = f\"{label},{prob * 100:.1f}%\"\n",
        "  cv2.rectangle(cropped, (x, y), (x + w, y + h), (0,255 , 0), 2)\n",
        "  cv2.putText(cropped, label_text, (x - 10, y - 10),cv2.FONT_HERSHEY_SIMPLEX,0.5, (0,255, 0), 1)\n",
        "# show the image\n",
        "plt.figure(figsize=(15,10))\n",
        "plt.imshow(cropped)"
      ],
      "metadata": {
        "id": "5JuT0AHAhGoy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}